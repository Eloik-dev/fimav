7767517
53 52
pnnx.Input               in0                      0 1 0 #0=(1,1,64,64)f32
pnnx.Expression          pnnx_expr_10             1 1 0 1 expr=div(sub(@0,127.500000),255.000000) #0=(1,1,64,64)f32 #1=(1,1,64,64)f32
nn.Conv2d                conv2d_0                 1 1 1 2 bias=False dilation=(1,1) groups=1 in_channels=1 kernel_size=(3,3) out_channels=64 padding=same padding_mode=zeros stride=(1,1) @weight=(64,1,3,3)f32 $input=1 #1=(1,1,64,64)f32 #2=(1,64,64,64)f32
pnnx.Attribute           Parameter4               0 1 3 @data=(64,1,1)f32 #3=(64,1,1)f32
pnnx.Expression          pnnx_expr_9              2 1 2 3 4 expr=add(@0,@1) #2=(1,64,64,64)f32 #3=(64,1,1)f32 #4=(1,64,64,64)f32
F.relu                   F.relu_4                 1 1 4 5 $input=4 #4=(1,64,64,64)f32 #5=(1,64,64,64)f32
nn.Conv2d                conv2d_1                 1 1 5 6 bias=False dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=same padding_mode=zeros stride=(1,1) @weight=(64,64,3,3)f32 $input=5 #5=(1,64,64,64)f32 #6=(1,64,64,64)f32
pnnx.Attribute           Parameter24              0 1 7 @data=(64,1,1)f32 #7=(64,1,1)f32
pnnx.Expression          pnnx_expr_8              2 1 6 7 8 expr=add(@0,@1) #6=(1,64,64,64)f32 #7=(64,1,1)f32 #8=(1,64,64,64)f32
F.relu                   F.relu_5                 1 1 8 9 $input=8 #8=(1,64,64,64)f32 #9=(1,64,64,64)f32
F.max_pool2d             F.max_pool2d_25          1 1 9 10 ceil_mode=False kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) $input=9 #9=(1,64,64,64)f32 #10=(1,64,32,32)f32
nn.Conv2d                conv2d_2                 1 1 10 11 bias=False dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=128 padding=same padding_mode=zeros stride=(1,1) @weight=(128,64,3,3)f32 $input=10 #10=(1,64,32,32)f32 #11=(1,128,32,32)f32
pnnx.Attribute           Parameter64              0 1 12 @data=(128,1,1)f32 #12=(128,1,1)f32
pnnx.Expression          pnnx_expr_7              2 1 11 12 13 expr=add(@0,@1) #11=(1,128,32,32)f32 #12=(128,1,1)f32 #13=(1,128,32,32)f32
F.relu                   F.relu_6                 1 1 13 14 $input=13 #13=(1,128,32,32)f32 #14=(1,128,32,32)f32
nn.Conv2d                conv2d_3                 1 1 14 15 bias=False dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=same padding_mode=zeros stride=(1,1) @weight=(128,128,3,3)f32 $input=14 #14=(1,128,32,32)f32 #15=(1,128,32,32)f32
pnnx.Attribute           Parameter84              0 1 16 @data=(128,1,1)f32 #16=(128,1,1)f32
pnnx.Expression          pnnx_expr_6              2 1 15 16 17 expr=add(@0,@1) #15=(1,128,32,32)f32 #16=(128,1,1)f32 #17=(1,128,32,32)f32
F.relu                   F.relu_7                 1 1 17 18 $input=17 #17=(1,128,32,32)f32 #18=(1,128,32,32)f32
F.max_pool2d             F.max_pool2d_26          1 1 18 19 ceil_mode=False kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) $input=18 #18=(1,128,32,32)f32 #19=(1,128,16,16)f32
nn.Conv2d                conv2d_4                 1 1 19 20 bias=False dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=256 padding=same padding_mode=zeros stride=(1,1) @weight=(256,128,3,3)f32 $input=19 #19=(1,128,16,16)f32 #20=(1,256,16,16)f32
pnnx.Attribute           Parameter576             0 1 21 @data=(256,1,1)f32 #21=(256,1,1)f32
pnnx.Expression          pnnx_expr_5              2 1 20 21 22 expr=add(@0,@1) #20=(1,256,16,16)f32 #21=(256,1,1)f32 #22=(1,256,16,16)f32
F.relu                   F.relu_8                 1 1 22 23 $input=22 #22=(1,256,16,16)f32 #23=(1,256,16,16)f32
nn.Conv2d                conv2d_5                 1 1 23 24 bias=False dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=same padding_mode=zeros stride=(1,1) @weight=(256,256,3,3)f32 $input=23 #23=(1,256,16,16)f32 #24=(1,256,16,16)f32
pnnx.Attribute           Parameter596             0 1 25 @data=(256,1,1)f32 #25=(256,1,1)f32
pnnx.Expression          pnnx_expr_4              2 1 24 25 26 expr=add(@0,@1) #24=(1,256,16,16)f32 #25=(256,1,1)f32 #26=(1,256,16,16)f32
F.relu                   F.relu_9                 1 1 26 27 $input=26 #26=(1,256,16,16)f32 #27=(1,256,16,16)f32
nn.Conv2d                conv2d_6                 1 1 27 28 bias=False dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=same padding_mode=zeros stride=(1,1) @weight=(256,256,3,3)f32 $input=27 #27=(1,256,16,16)f32 #28=(1,256,16,16)f32
pnnx.Attribute           Parameter616             0 1 29 @data=(256,1,1)f32 #29=(256,1,1)f32
pnnx.Expression          pnnx_expr_3              2 1 28 29 30 expr=add(@0,@1) #28=(1,256,16,16)f32 #29=(256,1,1)f32 #30=(1,256,16,16)f32
F.relu                   F.relu_10                1 1 30 31 $input=30 #30=(1,256,16,16)f32 #31=(1,256,16,16)f32
F.max_pool2d             F.max_pool2d_27          1 1 31 32 ceil_mode=False kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) $input=31 #31=(1,256,16,16)f32 #32=(1,256,8,8)f32
nn.Conv2d                conv2d_7                 1 1 32 33 bias=False dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=same padding_mode=zeros stride=(1,1) @weight=(256,256,3,3)f32 $input=32 #32=(1,256,8,8)f32 #33=(1,256,8,8)f32
pnnx.Attribute           Parameter656             0 1 34 @data=(256,1,1)f32 #34=(256,1,1)f32
pnnx.Expression          pnnx_expr_2              2 1 33 34 35 expr=add(@0,@1) #33=(1,256,8,8)f32 #34=(256,1,1)f32 #35=(1,256,8,8)f32
F.relu                   F.relu_11                1 1 35 36 $input=35 #35=(1,256,8,8)f32 #36=(1,256,8,8)f32
nn.Conv2d                conv2d_8                 1 1 36 37 bias=False dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=same padding_mode=zeros stride=(1,1) @weight=(256,256,3,3)f32 $input=36 #36=(1,256,8,8)f32 #37=(1,256,8,8)f32
pnnx.Attribute           Parameter676             0 1 38 @data=(256,1,1)f32 #38=(256,1,1)f32
pnnx.Expression          pnnx_expr_1              2 1 37 38 39 expr=add(@0,@1) #37=(1,256,8,8)f32 #38=(256,1,1)f32 #39=(1,256,8,8)f32
F.relu                   F.relu_12                1 1 39 40 $input=39 #39=(1,256,8,8)f32 #40=(1,256,8,8)f32
nn.Conv2d                conv2d_9                 1 1 40 41 bias=False dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=same padding_mode=zeros stride=(1,1) @weight=(256,256,3,3)f32 $input=40 #40=(1,256,8,8)f32 #41=(1,256,8,8)f32
pnnx.Attribute           Parameter696             0 1 42 @data=(256,1,1)f32 #42=(256,1,1)f32
pnnx.Expression          pnnx_expr_0              2 1 41 42 43 expr=add(@0,@1) #41=(1,256,8,8)f32 #42=(256,1,1)f32 #43=(1,256,8,8)f32
F.relu                   F.relu_13                1 1 43 44 $input=43 #43=(1,256,8,8)f32 #44=(1,256,8,8)f32
F.max_pool2d             F.max_pool2d_28          1 1 44 45 ceil_mode=False kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) $input=44 #44=(1,256,8,8)f32 #45=(1,256,4,4)f32
Tensor.reshape           Tensor.reshape_0         1 1 45 46 shape=(1,4096) $input=45 #45=(1,256,4,4)f32 #46=(1,4096)f32
nn.Linear                linear_0                 1 1 46 47 bias=True in_features=4096 out_features=1024 @bias=(1024)f32 @weight=(1024,4096)f32 $input=46 #46=(1,4096)f32 #47=(1,1024)f32
F.relu                   F.relu_14                1 1 47 48 $input=47 #47=(1,1024)f32 #48=(1,1024)f32
nn.Linear                linear_1                 1 1 48 49 bias=True in_features=1024 out_features=1024 @bias=(1024)f32 @weight=(1024,1024)f32 $input=48 #48=(1,1024)f32 #49=(1,1024)f32
F.relu                   F.relu_15                1 1 49 50 $input=49 #49=(1,1024)f32 #50=(1,1024)f32
nn.Linear                linear_2                 1 1 50 51 bias=True in_features=1024 out_features=8 @bias=(8)f32 @weight=(8,1024)f32 $input=50 #50=(1,1024)f32 #51=(1,8)f32
pnnx.Output              out0                     1 0 51 #51=(1,8)f32
